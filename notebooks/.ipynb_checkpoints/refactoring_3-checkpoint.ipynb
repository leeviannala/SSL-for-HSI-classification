{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77869fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import spectral\n",
    "import imageio\n",
    "import sklearn\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b29b5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gt(gt, train_size, mode='random'):\n",
    "    \"\"\"Extract a fixed percentage of samples from an array of labels.\n",
    "\n",
    "    Args:\n",
    "        gt: a 2D array of int labels\n",
    "        percentage: [0, 1] float\n",
    "    Returns:\n",
    "        train_gt, test_gt: 2D arrays of int labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    indices = np.nonzero(gt)\n",
    "    X = list(zip(*indices)) # x,y features\n",
    "    y = gt[indices].ravel() # classes\n",
    "    train_gt = np.zeros_like(gt)\n",
    "    test_gt = np.zeros_like(gt)\n",
    "    if train_size > 1:\n",
    "       train_size = int(train_size)\n",
    "    \n",
    "    if mode == 'random':\n",
    "       train_indices, test_indices = sklearn.model_selection.train_test_split(X, train_size=train_size, stratify=y)\n",
    "       train_indices = [list(t) for t in zip(*train_indices)]\n",
    "       test_indices = [list(t) for t in zip(*test_indices)]\n",
    "       train_gt[train_indices] = gt[train_indices]\n",
    "       test_gt[test_indices] = gt[test_indices]\n",
    "    elif mode == 'fixed':\n",
    "       # print(\"Sampling {} with train size = {}\".format(mode, train_size))\n",
    "       train_indices, test_indices = [], []\n",
    "       for c in np.unique(gt):\n",
    "           if c == 0:\n",
    "              continue\n",
    "           indices = np.nonzero(gt == c)\n",
    "           X = list(zip(*indices)) # x,y features\n",
    "           ##================\n",
    "           classsize = len(X)\n",
    "           train_size2=train_size\n",
    "           if classsize<=train_size:\n",
    "               train_size2=classsize-1\n",
    "           ##====================\n",
    "           train, test = sklearn.model_selection.train_test_split(X, train_size=train_size2)\n",
    "           train_indices += train\n",
    "           test_indices += test\n",
    "       train_indices = [list(t) for t in zip(*train_indices)]\n",
    "       test_indices = [list(t) for t in zip(*test_indices)]\n",
    "       train_gt[train_indices] = gt[train_indices]\n",
    "       test_gt[test_indices] = gt[test_indices]\n",
    "\n",
    "    elif mode == 'disjoint':\n",
    "        train_gt = np.copy(gt)\n",
    "        test_gt = np.copy(gt)\n",
    "        for c in np.unique(gt):\n",
    "            mask = gt == c\n",
    "            for x in range(gt.shape[0]):\n",
    "                first_half_count = np.count_nonzero(mask[:x, :])\n",
    "                second_half_count = np.count_nonzero(mask[x:, :])\n",
    "                try:\n",
    "                    ratio = first_half_count / second_half_count\n",
    "                    if ratio > 0.9 * train_size and ratio < 1.1 * train_size:\n",
    "                        break\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "            mask[:x, :] = 0\n",
    "            train_gt[mask] = 0\n",
    "\n",
    "        test_gt[train_gt > 0] = 0\n",
    "    else:\n",
    "        raise ValueError(\"{} sampling is not implemented yet.\".format(mode))\n",
    "    return train_gt, test_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6537967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(dataset): #TODO: implement opening dataset containing multiple files for tif files\n",
    "    _, ext = os.path.splitext(dataset)\n",
    "    ext = ext.lower()\n",
    "    if ext == '.mat':\n",
    "        # Load Matlab array\n",
    "        return io.loadmat(dataset)\n",
    "    elif ext == '.tif' or ext == '.tiff':\n",
    "        # Load TIFF file\n",
    "        return imageio.imread(dataset)\n",
    "    elif ext == '.hdr':\n",
    "        img = spectral.open_image(dataset)\n",
    "        return img.load()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown file format: {}\".format(ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4daa692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_CONFIG = {\n",
    "        'PaviaC': {\n",
    "            'urls': ['http://www.ehu.eus/ccwintco/uploads/e/e3/Pavia.mat', \n",
    "                     'http://www.ehu.eus/ccwintco/uploads/5/53/Pavia_gt.mat'],\n",
    "            'img': 'Pavia.mat',\n",
    "            'gt': 'Pavia_gt.mat'\n",
    "            },\n",
    "        'PaviaU': {\n",
    "            'urls': ['http://www.ehu.eus/ccwintco/uploads/e/ee/PaviaU.mat',\n",
    "                     'http://www.ehu.eus/ccwintco/uploads/5/50/PaviaU_gt.mat'],\n",
    "            'img': 'PaviaU.mat',\n",
    "            'gt': 'PaviaU_gt.mat'\n",
    "            },\n",
    "        'KSC': {\n",
    "            'urls': ['http://www.ehu.es/ccwintco/uploads/2/26/KSC.mat',\n",
    "                     'http://www.ehu.es/ccwintco/uploads/a/a6/KSC_gt.mat'],\n",
    "            'img': 'KSC.mat',\n",
    "            'gt': 'KSC_gt.mat'\n",
    "            },\n",
    "        'IndianPines': {\n",
    "            'urls': ['http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat',\n",
    "                     'http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat'],\n",
    "            'img': 'Indian_pines_corrected.mat',\n",
    "            'gt': 'Indian_pines_gt.mat'\n",
    "            },\n",
    "        'Botswana': {\n",
    "            'urls': ['http://www.ehu.es/ccwintco/uploads/7/72/Botswana.mat',\n",
    "                     'http://www.ehu.es/ccwintco/uploads/5/58/Botswana_gt.mat'],\n",
    "            'img': 'Botswana.mat',\n",
    "            'gt': 'Botswana_gt.mat',\n",
    "            },\n",
    "        'Houston': {\n",
    "            'urls': ['http://www.ehu.es/ccwintco/uploads/7/72/Botswana.mat',\n",
    "                 'http://www.ehu.es/ccwintco/uploads/5/58/Botswana_gt.mat'],\n",
    "            'img': 'Houston.mat',\n",
    "            'gt': 'Houston_gt.mat',\n",
    "            },\n",
    "        'hyrank': {\n",
    "            'urls': ['', ''],\n",
    "            'img': 'Training Set/Anafi.tif',\n",
    "            'gt': 'Training Set/Anafi_GT.tif'\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d0c90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_name, target_folder=\"./\", datasets=DATASETS_CONFIG):\n",
    "    # TODO: Add Hyrank\n",
    "    \"\"\" Gets the dataset specified by name and return the related components.\n",
    "    Args:\n",
    "        dataset_name: string with the name of the dataset\n",
    "        target_folder (optional): folder to store the datasets, defaults to ./\n",
    "        datasets (optional): dataset configuration dictionary, defaults to prebuilt one\n",
    "    Returns:\n",
    "        img: 3D hyperspectral image (WxHxB)\n",
    "        gt: 2D int array of labels\n",
    "        label_values: list of class names\n",
    "        ignored_labels: list of int classes to ignore\n",
    "        rgb_bands: int tuple that correspond to red, green and blue bands\n",
    "    \"\"\"\n",
    "    palette = None\n",
    "    \n",
    "    if dataset_name not in list(datasets.keys()):\n",
    "        raise ValueError(\"{} dataset is unknown.\".format(dataset_name))\n",
    "\n",
    "    dataset = datasets[dataset_name]\n",
    "\n",
    "    folder = target_folder + datasets[dataset_name].get('folder', dataset_name + '/')\n",
    "    if dataset.get('download', True):\n",
    "        # Download the dataset if is not present\n",
    "        if not os.path.isdir(folder):\n",
    "            os.mkdir(folder)\n",
    "        for url in datasets[dataset_name]['urls']:\n",
    "            # download the files\n",
    "            filename = url.split('/')[-1]\n",
    "            if not os.path.exists(folder + filename):\n",
    "                with TqdmUpTo(unit='B', unit_scale=True, miniters=1,\n",
    "                          desc=\"Downloading {}\".format(filename)) as t:\n",
    "                    urlretrieve(url, filename=folder + filename,\n",
    "                                     reporthook=t.update_to)\n",
    "    elif not os.path.isdir(folder):\n",
    "       print(\"WARNING: {} is not downloadable.\".format(dataset_name))\n",
    "\n",
    "    if dataset_name == 'PaviaC':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'Pavia.mat')['pavia']\n",
    "\n",
    "        rgb_bands = (55, 41, 12)\n",
    "\n",
    "        gt = open_file(folder + 'Pavia_gt.mat')['pavia_gt']\n",
    "\n",
    "        label_values = [\"Undefined\", \"Water\", \"Trees\", \"Asphalt\",\n",
    "                        \"Self-Blocking Bricks\", \"Bitumen\", \"Tiles\", \"Shadows\",\n",
    "                        \"Meadows\", \"Bare Soil\"]\n",
    "        all_labels = np.arange(len(label_values))\n",
    "\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "\n",
    "    elif dataset_name == 'PaviaU':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'PaviaU.mat')['paviaU']\n",
    "\n",
    "        rgb_bands = (55, 41, 12)\n",
    "\n",
    "        gt = open_file(folder + 'PaviaU_gt.mat')['paviaU_gt']\n",
    "\n",
    "        label_values = ['Undefined', 'Asphalt', 'Meadows', 'Gravel', 'Trees',\n",
    "                        'Painted metal sheets', 'Bare Soil', 'Bitumen',\n",
    "                        'Self-Blocking Bricks', 'Shadows']\n",
    "        all_labels = np.arange(len(label_values))\n",
    "\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "\n",
    "    elif dataset_name == 'IndianPines':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'Indian_pines_corrected.mat')\n",
    "        img = img['indian_pines_corrected']\n",
    "\n",
    "        rgb_bands = (43, 21, 11)  # AVIRIS sensor\n",
    "\n",
    "        gt = open_file(folder + 'Indian_pines_gt.mat')['indian_pines_gt']\n",
    "        label_values = [\"Undefined\", \"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\n",
    "                        \"Corn\", \"Grass-pasture\", \"Grass-trees\",\n",
    "                        \"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\n",
    "                        \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
    "                        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\n",
    "                        \"Stone-Steel-Towers\"]\n",
    "        all_labels = np.arange(len(label_values))\n",
    "\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'Houston':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'Houston.mat')\n",
    "        img = img['img']\n",
    "\n",
    "        rgb_bands = (43, 21, 11)  # AVIRIS sensor\n",
    "\n",
    "        gt = open_file(folder + 'Houston_gt.mat')['Houston_gt']\n",
    "        label_values = [\"Undefined\", \"1\", \"Corn-2\", \"Corn-3\",\n",
    "                        \"4\", \"Grass-5\", \"6-trees\",\n",
    "                        \"7-pasture-mowed\", \"Hay-8\", \"9\",\n",
    "                        \"Soybean-10\", \"11-mintill\", \"12-clean\",\n",
    "                        \"13\", \"14\", \"15-Grass-Trees-Drives\"]\n",
    "        all_labels = np.arange(len(label_values))\n",
    "\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'Botswana':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'Botswana.mat')['Botswana']\n",
    "\n",
    "        rgb_bands = (75, 33, 15)\n",
    "\n",
    "        gt = open_file(folder + 'Botswana_gt.mat')['Botswana_gt']\n",
    "        label_values = [\"Undefined\", \"Water\", \"Hippo grass\",\n",
    "                        \"Floodplain grasses 1\", \"Floodplain grasses 2\",\n",
    "                        \"Reeds\", \"Riparian\", \"Firescar\", \"Island interior\",\n",
    "                        \"Acacia woodlands\", \"Acacia shrublands\",\n",
    "                        \"Acacia grasslands\", \"Short mopane\", \"Mixed mopane\",\n",
    "                        \"Exposed soils\"]\n",
    "\n",
    "        all_labels = np.arange(len(label_values))\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'KSC':\n",
    "        # Load the image\n",
    "        img = open_file(folder + 'KSC.mat')['KSC']\n",
    "\n",
    "        rgb_bands = (43, 21, 11)  # AVIRIS sensor\n",
    "\n",
    "        gt = open_file(folder + 'KSC_gt.mat')['KSC_gt']\n",
    "        label_values = [\"Undefined\", \"Scrub\", \"Willow swamp\",\n",
    "                        \"Cabbage palm hammock\", \"Cabbage palm/oak hammock\",\n",
    "                        \"Slash pine\", \"Oak/broadleaf hammock\",\n",
    "                        \"Hardwood swamp\", \"Graminoid marsh\", \"Spartina marsh\",\n",
    "                        \"Cattail marsh\", \"Salt marsh\", \"Mud flats\", \"Wate\"]\n",
    "\n",
    "        all_labels = np.arange(len(label_values))\n",
    "        ignored_labels = [0]\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'hyrank':\n",
    "        files = ['Training Set/Anafi.tif',\n",
    "                 'Training Set/Atokos.tif',\n",
    "                 'Training Set/Donousa.tif',\n",
    "                 'Validation Set/Kasos.tif',\n",
    "                 'Validation Set/Tilos.tif',\n",
    "                ]\n",
    "        \n",
    "        files_gt = ['Training Set/Anafi_GT.tif',\n",
    "                    'Training Set/Atokos_GT.tif',\n",
    "                    'Training Set/Donousa_GT.tif',\n",
    "                    'Validation Set/Kasos_GT.tif',\n",
    "                    'Validation Set/Tilos_GT.tif',\n",
    "                    ]\n",
    "        img = [open_file(folder + i) for i in files]\n",
    "\n",
    "        rgb_bands = [30,20,2]\n",
    "\n",
    "        gt = [open_file(folder + i) for i in files_gt]\n",
    "\n",
    "        label_values = ['Undefined',\n",
    "                        'High intensity developed', \n",
    "                        'Med-low intensity developed',\n",
    "                        'Deciduous, Evergreen, mixed forest',\n",
    "                        'shrubland',\n",
    "                        'Grassland-Pasture',\n",
    "                        'Bareland',\n",
    "                        'water',\n",
    "                        'corn',\n",
    "                        'cotton',\n",
    "                        'cereals',\n",
    "                        'almonds',\n",
    "                        'grass fodders',\n",
    "                        'vinewards-grapes',\n",
    "                        'walnuts',\n",
    "                        'pistachios',\n",
    "                        'citrus',\n",
    "                        'fallow']\n",
    "\n",
    "        all_labels = np.arange(len(label_values))\n",
    "\n",
    "\n",
    "        ignored_labels = [0]\n",
    "    else:\n",
    "        # Custom dataset\n",
    "        img, gt, rgb_bands, ignored_labels, label_values, palette = CUSTOM_DATASETS_CONFIG[dataset_name]['loader'](folder)\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    # Filter NaN out\n",
    "    for i, im in enumerate(img):\n",
    "        nan_mask = np.isnan(im.sum(axis=-1))\n",
    "        if np.count_nonzero(nan_mask) > 0:\n",
    "            print(\"Warning: NaN have been found in the data. It is preferable to remove them beforehand. Learning on NaN data is disabled.\")\n",
    "            img[i][nan_mask] = 0\n",
    "            gt[i][nan_mask] = 0\n",
    "            ignored_labels.append(0)\n",
    "\n",
    "        # Normalization\n",
    "        im = np.asarray(im, dtype='float32')\n",
    "        #img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "        data = im.reshape(np.prod(im.shape[:2]), np.prod(im.shape[2:]))\n",
    "        #data = preprocessing.scale(data)\n",
    "        data  = preprocessing.minmax_scale(data)\n",
    "        img[i] = data.reshape(img.shape)\n",
    "    ignored_labels = list(set(ignored_labels))\n",
    "    return img, gt, label_values, ignored_labels, all_labels, rgb_bands, palette\n",
    "\n",
    "\n",
    "def get_originate_dataset(dataset_name, target_folder=\"./\", datasets=DATASETS_CONFIG):\n",
    "\n",
    "\n",
    "    if dataset_name not in list(datasets.keys()):\n",
    "        raise ValueError(\"{} dataset is unknown.\".format(dataset_name))\n",
    "\n",
    "    dataset = datasets[dataset_name]\n",
    "\n",
    "    folder = target_folder + datasets[dataset_name].get('folder', dataset_name + '/')\n",
    "\n",
    "\n",
    "    if dataset_name == 'PaviaC':\n",
    "        img = open_file(folder + 'Pavia.mat')['pavia']\n",
    "        gt = open_file(folder + 'Pavia_gt.mat')['pavia_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'PaviaU':\n",
    "        img = open_file(folder + 'PaviaU.mat')['paviaU']\n",
    "        gt = open_file(folder + 'PaviaU_gt.mat')['paviaU_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'IndianPines':\n",
    "        img = open_file(folder + 'Indian_pines_corrected.mat')\n",
    "        img = img['indian_pines_corrected']\n",
    "        rgb_bands = (43, 21, 11)  # AVIRIS sensor\n",
    "        gt = open_file(folder + 'Indian_pines_gt.mat')['indian_pines_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'Botswana':\n",
    "        img = open_file(folder + 'Botswana.mat')['Botswana']\n",
    "        gt = open_file(folder + 'Botswana_gt.mat')['Botswana_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'KSC':\n",
    "        img = open_file(folder + 'KSC.mat')['KSC']\n",
    "        gt = open_file(folder + 'KSC_gt.mat')['KSC_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'Houston':\n",
    "        img = open_file(folder + 'Houston.mat')\n",
    "        img = img['img']\n",
    "        gt = open_file(folder + 'Houston_gt.mat')['Houston_gt']\n",
    "        img = [img]\n",
    "        gt = [gt]\n",
    "    elif dataset_name == 'hyrank':\n",
    "        files = ['Training Set/Anafi.tif',\n",
    "                 'Training Set/Atokos.tif',\n",
    "                 'Training Set/Donousa.tif',\n",
    "                 'Validation Set/Kasos.tif',\n",
    "                 'Validation Set/Tilos.tif',\n",
    "                ]\n",
    "        \n",
    "        files_gt = ['Training Set/Anafi_GT.tif',\n",
    "                    'Training Set/Atokos_GT.tif',\n",
    "                    'Training Set/Donousa_GT.tif',\n",
    "                    'Validation Set/Kasos_GT.tif',\n",
    "                    'Validation Set/Tilos_GT.tif',\n",
    "                    ]\n",
    "        img = [open_file(folder + i) for i in files]\n",
    "        gt = [open_file(folder + i) for i in files_gt]\n",
    "    return img, gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99bbb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(DATASET, datasets_root, SAMPLE_PERCENTAGE):\n",
    "    img, gt, LABEL_VALUES, IGNORED_LABELS, ALL_LABELS, _, _ = get_dataset(DATASET, datasets_root)\n",
    "    X, Y = get_originate_dataset(DATASET, datasets_root)\n",
    "    img = np.concatenate(img)\n",
    "    img = img[:, :, list(range(0, 102, 3))] # Why is this here? This takes the every third channel from every dataset.\n",
    "                                            # The end point being fixed at 102 might be a problem. \n",
    "                                            # On the other hand no similar thing is done to X, which is supposedly\n",
    "                                            # the same image. \n",
    "\n",
    "    N_CLASSES = len(LABEL_VALUES)\n",
    "    INPUT_SIZE = np.shape(img)[-1]\n",
    "    # train_gt, test_gt = sample_gt(gt, SAMPLE_PERCENTAGE, mode='fixed')\n",
    "    train_test_gt = [sample_gt(i, SAMPLE_PERCENTAGE, mode='fixed') for i in gt]\n",
    "    #train_gt = sample_gt2(X, Y, train_gt, test_gt, SAMPLE_PERCENTAGE)\n",
    "    # # # breakpoint()\n",
    "    pseudo_labelpath= '../' + str(DATASET) + f'/pseudo_labels/pseudo_labels3/pseudo_labels3_{SAMPLE_PERCENTAGE}.npy'\n",
    "    pseudo_labels3 = []\n",
    "    if not os.path.exists(pseudo_labelpath):\n",
    "        newdir = str(DATASET) + '/pseudo_labels/pseudo_labels3/'\n",
    "        if not os.path.exists(newdir):\n",
    "            os.makedirs(newdir)\n",
    "        for x, y, tr_te_gt in zip(X, Y, train_test_gt):\n",
    "            pseudo_labels3.append(sample_gt3_new(x, y, tr_te_gt[0], tr_te_gt[1], \n",
    "                                                 SAMPLE_PERCENTAGE, IGNORED_LABELS, ALL_LABELS))\n",
    "        pseudo_labels3 = np.concatenate(pseudo_labels3)\n",
    "        np.save(pseudo_labelpath, pseudo_labels3)\n",
    "    else:\n",
    "        pseudo_labels3=np.load(pseudo_labelpath)\n",
    "    train_gt = np.concatenate([i[0] for i in train_test_gt])\n",
    "    test_gt = np.concatenate([i[1] for i in train_test_gt])\n",
    "    gt = np.concatenate(gt) \n",
    "    X = np.concatenate(X)\n",
    "    Y = np.concatenate(Y)\n",
    "    return img, gt, LABEL_VALUES, IGNORED_LABELS, ALL_LABELS, X, Y, N_CLASSES,\\\n",
    "           INPUT_SIZE, train_gt, test_gt, pseudo_labels3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87059de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000498/2054537087.py:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return imageio.imread(dataset)\n",
      "/tmp/ipykernel_1000498/2054537087.py:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  return imageio.imread(dataset)\n",
      "/tmp/ipykernel_1000498/1608058974.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  train_gt[train_indices] = gt[train_indices]\n",
      "/tmp/ipykernel_1000498/1608058974.py:46: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  test_gt[test_indices] = gt[test_indices]\n"
     ]
    }
   ],
   "source": [
    "img, gt, LABEL_VALUES, IGNORED_LABELS, ALL_LABELS,\\\n",
    "X, Y, N_CLASSES, INPUT_SIZE, train_gt, test_gt, pseudo_labels3 = load_datasets('hyrank', '/mnt/data/leevi/', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4b9b637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710, 34)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e8d94fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ba241d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Undefined',\n",
       " 'High intensity developed',\n",
       " 'Med-low intensity developed',\n",
       " 'Deciduous, Evergreen, mixed forest',\n",
       " 'shrubland',\n",
       " 'Grassland-Pasture',\n",
       " 'Bareland',\n",
       " 'water',\n",
       " 'corn',\n",
       " 'cotton',\n",
       " 'cereals',\n",
       " 'almonds',\n",
       " 'grass fodders',\n",
       " 'vinewards-grapes',\n",
       " 'walnuts',\n",
       " 'pistachios',\n",
       " 'citrus',\n",
       " 'fallow']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d04c8ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IGNORED_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e7cd14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8748c6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e8d59bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06ef6d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd42cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "979d9840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710, 18)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_labels3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd109531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710, 147)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4dfa6e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16640, 710)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4d3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
